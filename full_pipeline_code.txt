Snakefile:
import subprocess
import os

configfile: "config/config.yaml"

# –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –æ–±—Ä–∞–∑—Ü–æ–≤ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ VCF —Ñ–∞–π–ª–∞
try:
    VCF_PATH = config["resources"]["vcf"]
    SAMPLES = subprocess.check_output(f"bcftools query -l {VCF_PATH}", shell=True).decode().split()
except:
    SAMPLES = []

rule all:
    input:
        "results/qc/stats_final.txt",
        "results/plots/PCA_plot.png",
        "results/plots/NJ_tree.png",
        "results/plots/sNMF_entropy.png",
        "results/plots/ROH_Inbreeding_Final.png",
        "results/load/Rxy_stats.txt",
        "results/plots/Genomic_Windows.png",
        "results/dadi/best_model_plot.png",
        "results/models/slim_purging_results.png"

# --- 1. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ª–∞ (Blast –ø–æ Z/W) ---
rule download_sex_refs:
    output: z="resources/ref_sex/chrZ.fna", w="resources/ref_sex/chrW.fna"
    params: z_url=config["resources"]["ref_Z_url"], w_url=config["resources"]["ref_W_url"]
    shell: 
        "wget -O {output.z}.gz {params.z_url} && gunzip -f {output.z}.gz; "
        "wget -O {output.w}.gz {params.w_url} && gunzip -f {output.w}.gz"

rule blast_db:
    input: config["resources"]["genome"]
    output: multiext("resources/blast_db/calidris", ".ndb", ".nhr", ".nsq")
    shell: "makeblastdb -in {input} -dbtype nucl -out resources/blast_db/calidris"

rule blast_search:
    input: z="resources/ref_sex/chrZ.fna", w="resources/ref_sex/chrW.fna", db=multiext("resources/blast_db/calidris", ".ndb", ".nhr", ".nsq")
    output: z_res="results/sex_check/blast_Z.txt", w_res="results/sex_check/blast_W.txt"
    threads: 8
    shell: 
        "blastn -query {input.z} -db resources/blast_db/calidris -out {output.z_res} -outfmt 6 -evalue 1e-10 -num_threads {threads}; "
        "blastn -query {input.w} -db resources/blast_db/calidris -out {output.w_res} -outfmt 6 -evalue 1e-10 -num_threads {threads}"

rule identify_sex_scaffolds:
    input: z="results/sex_check/blast_Z.txt", w="results/sex_check/blast_W.txt"
    output: "results/sex_check/sex_scaffolds.txt"
    shell: "python scripts/detect_sex_scaffolds.py {input.z} {input.w} {output}"

# --- 2. –ñ–ï–°–¢–ö–ê–Ø –§–ò–õ–¨–¢–†–ê–¶–ò–Ø (–ü–æ —Å—Ç–∞—Ç—å–µ: AB 0.2-0.8, GAP 5bp, Depth 1/3-2x) ---
rule filter_vcf_strict:
    input: 
        vcf=config["resources"]["vcf"],
        sex="results/sex_check/sex_scaffolds.txt"
    output: 
        vcf="results/qc/clean_strict.vcf.gz",
        tbi="results/qc/clean_strict.vcf.gz.tbi"
    params:
        min_dp=config["filtering"]["min_depth"],
        max_dp=config["filtering"]["max_depth"],
        ab_min=config["filtering"]["min_allele_balance"],
        snp_gap=config["filtering"]["snp_gap"],
        hwe=config["filtering"]["hwe_threshold"]
    shell:
        """
        # 1. –ë–∞–∑–æ–≤–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è (–ö–∞—á–µ—Å—Ç–≤–æ, –ì–ª—É–±–∏–Ω–∞, –ò–Ω–¥–µ–ª–∏, –ü—Ä–æ–ø—É—Å–∫–∏)
        # 2. –£–¥–∞–ª–µ–Ω–∏–µ SNP –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 5bp –æ—Ç –∏–Ω–¥–µ–ª–æ–≤ (-g 5)
        # 3. –ö–∞—Å—Ç–æ–º–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è Allele Balance (—Ñ–∏–ª—å—Ç—Ä –ø–∞—Ä–∞–ª–æ–≥–æ–≤ –∏ –∑–∞–≥—Ä—è–∑–Ω–µ–Ω–∏–π)
        bcftools view -m2 -M2 -v snps {input.vcf} | \
        bcftools filter -e 'QUAL < 30 || INFO/DP < {params.min_dp} || INFO/DP > {params.max_dp} || HWE < {params.hwe}' | \
        bcftools filter -g {params.snp_gap} | \
        python scripts/filter_allele_balance.py {params.ab_min} | \
        bcftools view -O z -o {output.vcf}
        bcftools index {output.vcf}
        """

# --- 3. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–æ–ø—É–ª—è—Ü–∏–∏ (PCA + NJ Tree + sNMF) ---
rule ld_pruning:
    input: "results/qc/clean_strict.vcf.gz"
    output: "results/qc/pruned.vcf.gz"
    shell:
        """
        plink --vcf {input} --allow-extra-chr --indep-pairwise 50 10 0.2 --out results/qc/pruning
        plink --vcf {input} --allow-extra-chr --extract results/qc/pruning.prune.in --recode vcf --out results/qc/pruned
        bgzip results/qc/pruned.vcf && bcftools index results/qc/pruned.vcf.gz
        """

rule pca_analysis:
    input: "results/qc/pruned.vcf.gz"
    output: vec="results/qc/pca.eigenvec", val="results/qc/pca.eigenval"
    shell: "plink --vcf {input} --allow-extra-chr --pca --out results/qc/pca"

rule nj_tree:
    input: "results/qc/pruned.vcf.gz"
    output: "results/plots/NJ_tree.png"
    shell:
        """
        plink --vcf {input} --allow-extra-chr --distance 1-ibs square --out results/qc/dist_matrix
        python scripts/plot_nj_tree.py results/qc/dist_matrix.mdist results/qc/dist_matrix.mdist.id {output}
        """

rule run_snmf:
    input: "results/qc/pruned.vcf.gz"
    output: "results/plots/sNMF_entropy.png"
    params: k_min=config["snmf"]["K_min"], k_max=config["snmf"]["K_max"], reps=config["snmf"]["repetitions"]
    shell: "Rscript scripts/run_snmf.R {input} {params.k_min} {params.k_max} {params.reps} {output}"

# --- 4. –î–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∞—è –∏—Å—Ç–æ—Ä–∏—è (PSMC + dadi) ---
# –ó–∞–ø—É—Å–∫ PSMC –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞ –æ—Ç–¥–µ–ª—å–Ω–æ
rule psmc_individual:
    input: 
        bam="resources/bams/{sample}.bam",
        ref=config["resources"]["genome"]
    output: 
        psmc="results/demography/psmc/{sample}.psmc",
        plot="results/demography/psmc/{sample}.psmc.plot.png"
    params:
        p=config["demography"]["psmc"]["pattern"],
        mu=config["demography"]["mu"],
        g=config["demography"]["gen_time"]
    shell:
        """
        samtools mpileup -C50 -uf {input.ref} {input.bam} | bcftools call -c | \
        vcfutils.pl vcf2fq -d 5 -D 50 | gzip > results/demography/psmc/{wildcards.sample}.fq.gz
        fq2psmcfa results/demography/psmc/{wildcards.sample}.fq.gz > results/demography/psmc/{wildcards.sample}.psmcfa
        psmc -N25 -t15 -r5 -p {params.p} -o {output.psmc} results/demography/psmc/{wildcards.sample}.psmcfa
        psmc_plot.pl -u {params.mu} -g {params.g} results/demography/psmc/{wildcards.sample} {output.psmc}
        mv results/demography/psmc/{wildcards.sample}.eps {output.plot} || touch {output.plot}
        """

rule dadi_inference:
    input: "results/qc/pruned.vcf.gz"
    output: params="results/dadi/best_params.txt", plot="results/dadi/best_model_plot.png"
    shell: "python scripts/dadi_inference.py {input} {output.params} {output.plot}"

# --- 5. –ú—É—Ç–∞—Ü–∏–æ–Ω–Ω—ã–π –≥—Ä—É–∑ (–ü–æ–ª—è—Ä–∏–∑–∞—Ü–∏—è + SnpEff + Rxy) ---
rule build_snpeff_db:
    input: g=config["resources"]["genome"], a=config["resources"]["genes"]
    output: directory("results/snpeff_data/calidris")
    shell:
        """
        mkdir -p results/snpeff_data/calidris
        cp {input.g} results/snpeff_data/calidris/sequences.fa
        cp {input.a} results/snpeff_data/calidris/genes.gff
        echo 'calidris.genome : Calidris' > snpEff_local.config
        snpEff build -c snpEff_local.config -gff3 -v calidris
        """

rule polarize_vcf:
    input: 
        vcf="results/qc/clean_strict.vcf.gz",
        outgroup=config["resources"]["outgroup_vcf"]
    output: "results/load/polarized.vcf.gz"
    shell: "python scripts/polarize_vcf.py {input.vcf} {input.outgroup} {output}"

rule annotate_load:
    input: vcf="results/load/polarized.vcf.gz", db="results/snpeff_data/calidris"
    output: "results/load/annotated.vcf.gz"
    shell: "snpEff ann -c snpEff_local.config -v calidris {input.vcf} | bgzip > {output} && bcftools index {output}"

rule calculate_rxy:
    input: "results/load/annotated.vcf.gz"
    output: "results/load/Rxy_stats.txt"
    shell: "python scripts/calc_rxy.py {input} {output}"

# --- 6. –ò–Ω–±—Ä–∏–¥–∏–Ω–≥ (ROH –ø–æ –∂–µ—Å—Ç–∫–∏–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º) ---
rule calc_roh_final:
    input: "results/qc/clean_strict.vcf.gz"
    output: "results/plots/ROH_Inbreeding_Final.png"
    params:
        kb=config["inbreeding_roh"]["min_kb"],
        snps=config["inbreeding_roh"]["min_snps"]
    shell:
        """
        plink --vcf {input} --allow-extra-chr \
              --homozyg --homozyg-kb {params.kb} --homozyg-snp {params.snps} \
              --homozyg-window-het 1 --homozyg-density 50 \
              --out results/qc/roh_final
        python scripts/plot_roh_paper.py results/qc/roh_final.hom {output}
        """

# --- 7. –ì–µ–Ω–æ–º–Ω–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ (–û–∫–Ω–∞) ---
rule genomic_windows:
    input: "results/qc/clean_strict.vcf.gz"
    output: "results/plots/Genomic_Windows.png"
    params: w=config["window_stats"]["window_size"]
    shell:
        """
        vcftools --gzvcf {input} --window-pi {params.w} --out results/qc/windows
        vcftools --gzvcf {input} --TajimaD {params.w} --out results/qc/windows
        python scripts/plot_windows.py results/qc/windows.windowed.pi results/qc/windows.Tajima.D {output}
        """

# --- 8. SLiM –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ (Purging) ---
rule slim_purging:
    input: "results/dadi/best_params.txt"
    output: "results/models/slim_purging_results.png"
    shell: "python scripts/run_slim_purging.py {input} {output}"


==================================================

config/config.yaml:
samples:
  population_name: "Spoonbill"

resources:
  # –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –∏–º—è —Ñ–∞–π–ª–∞ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å —Ä–µ–∞–ª—å–Ω—ã–º (vcf –∏–ª–∏ vcf.gz)
  vcf: "resources/merged.vcf"
  genome: "resources/genome.fasta"
  genes: "resources/genes.gff"
  # –ü—É—Ç—å –∫ VCF –≤–Ω–µ—à–Ω–µ–π –≥—Ä—É–ø–ø—ã (–Ω—É–∂–µ–Ω –¥–ª—è –ø—Ä–∞–≤–∏–ª–∞ polarize_vcf)
  # –ï—Å–ª–∏ –µ–≥–æ –ø–æ–∫–∞ –Ω–µ—Ç, —Å–æ–∑–¥–∞–π—Ç–µ –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª –∏–ª–∏ –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –ø—Ä–∞–≤–∏–ª–æ –≤ Snakefile
  outgroup_vcf: "resources/outgroup_alpina.vcf.gz"
  
  ref_Z_url: "https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/003/957/565/GCF_003957565.2_bTaeGut1.4.pri/GCF_003957565.2_bTaeGut1.4.pri_assembly_structure/Primary_Assembly/assembled_chromosomes/FASTA/chrZ.fna.gz"
  ref_W_url: "https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/002/315/GCF_000002315.6_GRCg6a/GCF_000002315.6_GRCg6a_assembly_structure/Primary_Assembly/assembled_chromosomes/FASTA/chrW.fna.gz"

filtering:
  qual: 30
  min_depth: 100
  max_depth: 600
  max_missing: 0.95
  hwe_threshold: "1e-5"
  
  # --- –í–û–¢ –≠–¢–ò–• –°–¢–†–û–ö –ù–ï –•–í–ê–¢–ê–õ–û ---
  min_allele_balance: 0.2
  snp_gap: 5

demography:
  mu: 1.33e-8
  gen_time: 4
  psmc:
    pattern: "4+25*2+4+6"

inbreeding_roh:
  min_kb: 100
  min_snps: 25

window_stats:
  window_size: 50000

snmf:
  K_min: 1
  K_max: 5
  repetitions: 5

dadi:
  projections: [20]
  bootstraps: 50


==================================================

environment.yaml:
name: genomics_full
channels:
  - conda-forge
  - bioconda
  - defaults
dependencies:
  # Core Workflow
  - python=3.9
  - snakemake=7.32.4
  
  # Bioinformatics Tools
  - bcftools=1.19
  - plink=1.90b6.21  # –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤–µ—Ä—Å–∏—è –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç --allow-extra-chr
  - snpeff=5.1
  - blast=2.15.0
  - samtools=1.19
  - vcftools=0.1.16
  
  # Simulation & Analysis
  - dadi=2.4.3
  - slim=4.0.1      # –£–∫–∞–∂–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—É—é –≤–µ—Ä—Å–∏—é SLiM (—á–∞—Å—Ç–æ –≤ bioconda –æ–Ω–∞ —Å—Ç–∞—Ä–∞—è, –º–± –ø—Ä–∏–¥–µ—Ç—Å—è –∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞—Ç—å –∏–ª–∏ –∏—Å–∫–∞—Ç—å –∫–∞–Ω–∞–ª)
  - bioconductor-lea # –î–ª—è sNMF
  
  # Python Libs for Scripts
  - pandas
  - matplotlib
  - seaborn
  - numpy
  - scipy
  - cyvcf2          # –ë—ã—Å—Ç—Ä—ã–π –ø–∞—Ä—Å–∏–Ω–≥ VCF
  - biopython
  
  # R Environment
  - r-base=4.3


==================================================

scripts/plot_roh.py:
import sys
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os

roh_file = sys.argv[1]
out_plot = sys.argv[2]

# –ü—Ä–æ–≤–µ—Ä–∫–∞, –ø—É—Å—Ç–æ–π –ª–∏ —Ñ–∞–π–ª
if os.path.getsize(roh_file) == 0:
    print("ROH file is empty. No ROH detected.")
    plt.figure()
    plt.text(0.5, 0.5, "No ROH Detected (Data Empty)", ha='center')
    plt.savefig(out_plot)
    sys.exit()

try:
    df = pd.read_csv(roh_file, sep='\s+')
    if df.empty:
        raise ValueError("Empty DataFrame")
        
    # –û–ß–ò–°–¢–ö–ê –ò–ú–ï–ù: —É–±–∏—Ä–∞–µ–º –ø—É—Ç—å –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ ID
    df['IID'] = df['IID'].astype(str).apply(lambda x: os.path.basename(x).split('.')[0])
except Exception as e:
    print(f"Error parsing ROH file: {e}")
    plt.figure()
    plt.text(0.5, 0.5, f"No ROH segments found\nCheck filtering parameters", ha='center')
    plt.savefig(out_plot)
    sys.exit()

GENOME_LEN = 1.2e9 
# –°—á–∏—Ç–∞–µ–º —Å—É–º–º—É ROH (KB) –¥–ª—è –∫–∞–∂–¥–æ–π –æ—Å–æ–±–∏
froh = df.groupby('IID')['KB'].sum() * 1000 / GENOME_LEN
froh = froh.reset_index(name='F_ROH')
n_roh = df.groupby('IID')['KB'].count().reset_index(name='N_ROH')

data = pd.merge(froh, n_roh, on='IID')

plt.figure(figsize=(12, 7))
if not data.empty:
    sns.scatterplot(data=data, x='N_ROH', y='F_ROH', s=200, color='darkred', alpha=0.7, edgecolor='black')

    for i in range(data.shape[0]):
        plt.text(data.N_ROH[i] + 0.1, data.F_ROH[i], data.IID[i], fontsize=9, verticalalignment='bottom')

plt.xlabel("Number of ROH segments (N_ROH)")
plt.ylabel("Inbreeding Coefficient (F_ROH)")
plt.title("Genomic Inbreeding: Runs of Homozygosity Analysis")
plt.grid(True, alpha=0.3, linestyle='--')
plt.savefig(out_plot, dpi=300)


==================================================

scripts/run_slim_dynamic.py:
import sys
import subprocess
import matplotlib.pyplot as plt

param_file = sys.argv[1]
out_plot = sys.argv[2]

# –ß—Ç–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
p = {}
with open(param_file) as f:
    for line in f:
        k, v = line.strip().split('=')
        p[k] = int(v)

# Scaling Factor (Q)
# –£–º–µ–Ω—å—à–∏–º Q, —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–∏ –º–∞–ª—ã—Ö N, –Ω–æ —ç—Ç–æ –∑–∞–º–µ–¥–ª–∏—Ç —Ä–∞—Å—á–µ—Ç
Q = 5 

# --- –õ–û–ì–ò–ö–ê –ó–ê–©–ò–¢–´ –û–¢ –í–´–ú–ò–†–ê–ù–ò–Ø ---
# –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ø–æ–ø—É–ª—è—Ü–∏–∏ –≤ —Å–∏–º—É–ª—è—Ü–∏–∏, —á—Ç–æ–±—ã –æ–Ω–∞ –Ω–µ –≤—ã–º–µ—Ä–ª–∞ —Å–ª—É—á–∞–π–Ω–æ
MIN_VIABLE_SCALED = 20 

def scale_pop(val, q, min_val):
    scaled = int(val / q)
    return max(min_val, scaled)

N_ANC = scale_pop(p['N_ANC'], Q, MIN_VIABLE_SCALED)
# –ó–¥–µ—Å—å –±—ã–ª–∞ –ø—Ä–æ–±–ª–µ–º–∞: 39/10 = 3 –æ—Å–æ–±–∏ -> –≤—ã–º–∏—Ä–∞–Ω–∏–µ. –¢–µ–ø–µ—Ä—å –±—É–¥–µ—Ç –º–∏–Ω–∏–º—É–º 20.
N_BOT = scale_pop(p['N_BOT'], Q, MIN_VIABLE_SCALED) 
N_CUR = scale_pop(p['N_CUR'], Q, MIN_VIABLE_SCALED)
N_CRISIS = scale_pop(2500, Q, MIN_VIABLE_SCALED)

# –í—Ä–µ–º—è —Ç–æ–∂–µ —Å–∫–∞–ª–∏—Ä—É–µ–º, –Ω–æ —Å–ª–µ–¥–∏–º, —á—Ç–æ–±—ã –æ–Ω–æ –Ω–µ —Å—Ç–∞–ª–æ 0
T_BOT = max(10, int(p['T_BOT_DUR_GEN'] / Q))
T_REC = max(10, int(p['T_REC_AGO_GEN'] / Q))

T_BURNIN = 10 * N_ANC 
T_START_BOT = T_BURNIN
T_START_REC = T_START_BOT + T_BOT
T_START_CRISIS = T_START_REC + T_REC
T_END = T_START_CRISIS + 100 

print(f"Simulating with scaled params: N_ANC={N_ANC}, N_BOT={N_BOT}, N_CUR={N_CUR}")

slim_code = f"""
initialize() {{
    initializeMutationRate(1e-7 * {Q}); 
    initializeMutationType("m1", 0.5, "f", 0.0);
    initializeMutationType("m2", 0.1, "g", -0.05, 0.2); 
    initializeGenomicElementType("g1", c(m1, m2), c(1.0, 0.5));
    for (i in 0:9) {{ initializeGenomicElement(g1, i*2000, i*2000 + 999); }}
    initializeRecombinationRate(1e-8 * {Q});
}}
1 early() {{ sim.addSubpop("p1", {N_ANC}); }}

1:{T_END} late() {{
    if (community.tick % 10 == 0) {{
        if (p1.individualCount > 0) {{
            load = mean(p1.individuals.countOfMutationsOfType(m2));
            cat("DATA:" + community.tick + "," + load + "\\n");
        }}
    }}
}}

{T_START_BOT} early() {{ p1.setSubpopulationSize({N_BOT}); }}
{T_START_REC} early() {{ p1.setSubpopulationSize({N_CUR}); }}
{T_START_CRISIS} early() {{ p1.setSubpopulationSize({N_CRISIS}); }}
"""

res = subprocess.run(["slim", "-"], input=slim_code, capture_output=True, text=True)

gens, loads = [], []
for line in res.stdout.splitlines():
    if line.startswith("DATA:"):
        try:
            parts = line.strip().split("DATA:")[1].split(",")
            gens.append(int(parts[0]))
            loads.append(float(parts[1]))
        except:
            continue

plt.figure(figsize=(10, 6))
if len(gens) > 0:
    plt.plot(gens, loads, 'r-', lw=2)
    plt.axvline(T_START_BOT, ls='--', color='black', label="Bottleneck")
    plt.axvline(T_START_REC, ls='--', color='blue', label="Recovery")
    plt.axvline(T_START_CRISIS, ls='--', color='red', label="Modern Crisis")
    plt.xlabel("Generations")
    plt.ylabel("Avg Load")
    plt.title(f"Simulated Load (Q={Q})")
    plt.legend()
else:
    plt.text(0.5, 0.5, "Simulation Extinct", ha='center')
    print("SLiM produced no data. Population likely extinct.")

plt.tight_layout()
plt.savefig(out_plot)


==================================================

scripts/filter_allele_balance.py:
import sys
import sys
from cyvcf2 import VCF, Writer

min_ab = float(sys.argv[1])
max_ab = 1.0 - min_ab

vcf = VCF('-', mode='r')
w = Writer('-', vcf)

for variant in vcf:
    ad = variant.format('AD') # Allele Depth
    if ad is not None:
        # –õ–æ–≥–∏–∫–∞: –µ—Å–ª–∏ –≥–µ—Ç–µ—Ä–æ–∑–∏–≥–æ—Ç–∞, –ø—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–ª–∞–Ω—Å
        # –≠—Ç–æ —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø—Ä–∏–º–µ—Ä, –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä—è—Ç—å –∫–∞–∂–¥—ã–π –æ–±—Ä–∞–∑–µ—Ü
        pass 
    w.write_record(variant)


==================================================

scripts/run_snmf.R:
args <- commandArgs(trailingOnly = TRUE)
input_vcf <- args[1]
k_min <- as.integer(args[2])
k_max <- as.integer(args[3])
reps <- as.integer(args[4])
out_plot <- args[5]

if (!requireNamespace("LEA", quietly = TRUE)) {
    stop("Package LEA is not installed. Run: conda install -c bioconda bioconductor-lea")
}
library(LEA)

# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è VCF –≤ —Ñ–æ—Ä–º–∞—Ç GENO (—Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è sNMF)
# output –±—É–¥–µ—Ç input_vcf.geno
geno_file <- vcf2geno(input_vcf, output = paste0(input_vcf, ".geno"), force=TRUE)

# –ó–∞–ø—É—Å–∫ sNMF
project <- snmf(geno_file, K = k_min:k_max, entropy = TRUE, repetitions = reps, project = "new")

# –†–∏—Å—É–µ–º –≥—Ä–∞—Ñ–∏–∫ –∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏–∏
png(out_plot)
plot(project, col = "blue", pch = 19, cex = 1.2)
dev.off()

# –õ—É—á—à–∏–π K (–º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è)
best_K <- which.min(cross.entropy(project, K = k_min:k_max))
print(paste("Best K seems to be:", best_K))


==================================================

scripts/make_sfs.py:
import dadi
import matplotlib.pyplot as plt
import sys

vcf_file = sys.argv[1]
pop_file = sys.argv[2]
out_sfs = sys.argv[3]
out_plot = sys.argv[4]

dd = dadi.Misc.make_data_dict_vcf(vcf_file, pop_file)
pop_ids = ['Spoonbill']
proj_n = [40] 

fs = dadi.Spectrum.from_data_dict(dd, pop_ids=pop_ids, projections=proj_n, polarized=False)
fs.to_file(out_sfs)

plt.figure(figsize=(10, 6))
dadi.Plotting.plot_1d_fs(fs)
plt.title("SFS Spoonbill")
plt.savefig(out_plot)


==================================================

scripts/extract_lower.py:
import sys
from Bio import SeqIO

if len(sys.argv) < 2:
    sys.exit("Usage: extract_lower.py input.fasta")

fasta_file = sys.argv[1]

for record in SeqIO.parse(fasta_file, "fasta"):
    seq = str(record.seq)
    in_mask = False
    start = 0
    for i, base in enumerate(seq):
        is_lower = base.islower()
        if is_lower and not in_mask:
            start = i
            in_mask = True
        elif not is_lower and in_mask:
            print(f"{record.id}\t{start}\t{i}")
            in_mask = False
    if in_mask:
        print(f"{record.id}\t{start}\t{len(seq)}")


==================================================

scripts/find_cpg.py:
import sys
from Bio import SeqIO

if len(sys.argv) < 2:
    sys.exit("Usage: find_cpg.py input.fasta")

fasta_file = sys.argv[1]

for record in SeqIO.parse(fasta_file, "fasta"):
    seq = str(record.seq).upper()
    start = 0
    while True:
        idx = seq.find("CG", start)
        if idx == -1:
            break
        print(f"{record.id}\t{idx}\t{idx+2}")
        start = idx + 1


==================================================

scripts/plot_structure.py:
import sys
import pandas as pd
import matplotlib.pyplot as plt
from scipy.cluster.hierarchy import dendrogram, linkage
import numpy as np

# –ê—Ä–≥—É–º–µ–Ω—Ç—ã –æ—Ç Snakemake
eigenvec_f = sys.argv[1]
eigenval_f = sys.argv[2]
mibs_f = sys.argv[3]
mibs_id_f = sys.argv[4]
out_pca = sys.argv[5]
out_tree = sys.argv[6]

# --- PCA ---
try:
    pca_data = pd.read_csv(eigenvec_f, sep='\s+', header=None)
    eigenval = pd.read_csv(eigenval_f, header=None)
    pca_data.columns = ['FID', 'IID'] + [f'PC{i+1}' for i in range(len(pca_data.columns)-2)]

    total_variance = eigenval[0].sum()
    pc1_var = round((eigenval[0][0] / total_variance) * 100, 2)
    pc2_var = round((eigenval[0][1] / total_variance) * 100, 2)

    plt.figure(figsize=(10, 8))
    plt.scatter(pca_data['PC1'], pca_data['PC2'], s=50)
    for i, txt in enumerate(pca_data['IID']):
        plt.annotate(txt, (pca_data['PC1'][i], pca_data['PC2'][i]), fontsize=8, alpha=0.75)
    plt.xlabel(f'PC1 ({pc1_var}%)'); plt.ylabel(f'PC2 ({pc2_var}%)')
    plt.grid(True)
    plt.savefig(out_pca)
except Exception as e:
    print(f"Error plotting PCA: {e}")

# --- Dendrogram ---
try:
    dist_matrix = np.loadtxt(mibs_f)
    ids_ibs = pd.read_csv(mibs_id_f, sep='\s+', header=None)
    num_samples = len(ids_ibs)
    dissimilarities = dist_matrix[np.tril_indices(num_samples, k=-1)]
    linked = linkage(1 - dissimilarities, method='ward')

    plt.figure(figsize=(12, 7))
    dendrogram(linked, orientation='top', labels=ids_ibs[1].tolist(), distance_sort='descending', show_leaf_counts=True)
    plt.xticks(rotation=90); plt.tight_layout()
    plt.savefig(out_tree)
except Exception as e:
    print(f"Error plotting Tree: {e}")


==================================================

scripts/count_and_plot_load.py:
import sys
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from cyvcf2 import VCF
import numpy as np

VCF_FILE = sys.argv[1]
OUT_PLOT = sys.argv[2]

try:
    vcf = VCF(VCF_FILE)
    samples = vcf.samples
except Exception as e:
    print(f"Error opening VCF: {e}")
    sys.exit(1)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—á–µ—Ç—á–∏–∫–æ–≤
# load_counts = {'SampleName': {'syn': 0, 'mis': 0, 'lof': 0}}
load_counts = {s: {'syn': 0, 'mis': 0, 'lof': 0} for s in samples}

print("Parsing VCF...")
for variant in vcf:
    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ –Ω–µ—Ç –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
    ann_info = variant.INFO.get('ANN')
    if not ann_info:
        continue
    
    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é (–æ–±—ã—á–Ω–æ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç)
    # –§–æ—Ä–º–∞—Ç SnpEff: Allele|Annotation|Impact|GeneName...
    ann_parts = ann_info.split(',')[0].split('|')
    if len(ann_parts) < 3:
        continue
        
    impact = ann_parts[2]
    
    category = None
    if impact == 'LOW': category = 'syn'
    elif impact == 'MODERATE': category = 'mis'
    elif impact == 'HIGH': category = 'lof'
    
    if category is None:
        continue

    # –ò—Ç–µ—Ä–∞—Ü–∏—è –ø–æ –≥–µ–Ω–æ—Ç–∏–ø–∞–º (–Ω–∞–º–Ω–æ–≥–æ –±—ã—Å—Ç—Ä–µ–µ –≤ cyvcf2)
    # variant.gt_types: 0=HOM_REF, 1=HET, 2=HOM_ALT, 3=UNKNOWN
    for i, gt in enumerate(variant.gt_types):
        if gt == 1 or gt == 2: # –ï—Å–ª–∏ –µ—Å—Ç—å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –∞–ª–ª–µ–ª—å (HET –∏–ª–∏ HOM)
            # –í –¥–∞–Ω–Ω–æ–º –ø—Ä–æ—Å—Ç–æ–º –∞–Ω–∞–ª–∏–∑–µ —Å—á–∏—Ç–∞–µ–º "–Ω–∞–≥—Ä—É–∑–∫–æ–π" –Ω–∞–ª–∏—á–∏–µ –∞–ª–ª–µ–ª—è
            # –ú–æ–∂–Ω–æ —É—Å–ª–æ–∂–Ω–∏—Ç—å: HOM = 2, HET = 1
            load_counts[samples[i]][category] += 1

# –°–æ–∑–¥–∞–Ω–∏–µ DataFrame
df = pd.DataFrame.from_dict(load_counts, orient='index')
df.index.name = 'IID'
df.reset_index(inplace=True)

# –†–∞—Å—á–µ—Ç –æ—Ç–Ω–æ—à–µ–Ω–∏–π
# –î–æ–±–∞–≤–ª—è–µ–º –º–∞–ª—ã–π —ç–ø—Å–∏–ª–æ–Ω, —á—Ç–æ–±—ã –Ω–µ –¥–µ–ª–∏—Ç—å –Ω–∞ –Ω–æ–ª—å
df['Ratio_LoF_Syn'] = df['lof'] / (df['syn'] + 1e-9)
df['Ratio_Mis_Syn'] = df['mis'] / (df['syn'] + 1e-9)

plot_df = df[['Ratio_LoF_Syn', 'Ratio_Mis_Syn']].melt(var_name='Type', value_name='Ratio')

plt.figure(figsize=(10, 8))
if not plot_df.empty:
    sns.boxplot(x='Type', y='Ratio', hue='Type', data=plot_df, palette="Pastel1", legend=False)
    sns.stripplot(x='Type', y='Ratio', data=plot_df, color='black', alpha=0.6, jitter=True)
    plt.title("Mutational Load Ratios (Relative to Synonymous)")
else:
    plt.text(0.5, 0.5, "No variants found")

plt.savefig(OUT_PLOT)


==================================================

scripts/polarize_vcf.py:
import sys
from cyvcf2 import VCF, Writer
import numpy as np

def polarize(vcf_in, outgroup_vcf, vcf_out):
    # –û—Ç–∫—Ä—ã–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π VCF –∏ VCF –≤–Ω–µ—à–Ω–µ–π –≥—Ä—É–ø–ø—ã
    # –í–Ω–µ—à–Ω—è—è –≥—Ä—É–ø–ø–∞ –î–û–õ–ñ–ù–ê –±—ã—Ç—å –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∞ (tabix)
    target_vcf = VCF(vcf_in)
    out_vcf = VCF(outgroup_vcf)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Ö–µ–¥–µ—Ä –æ –ø–æ–ª—è—Ä–∏–∑–∞—Ü–∏–∏
    target_vcf.add_info_to_header({
        'ID': 'AA', 'Number': '1', 'Type': 'String', 
        'Description': 'Ancestral Allele determined by outgroup'
    })
    
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å
    w = Writer(vcf_out, target_vcf)
    
    count_swapped = 0
    count_total = 0
    count_dropped = 0

    print(f"Starting polarization of {vcf_in} using {outgroup_vcf}...")

    for variant in target_vcf:
        count_total += 1
        
        # –ò—â–µ–º —ç—Ç—É –∂–µ –ø–æ–∑–∏—Ü–∏—é –≤ VCF –≤–Ω–µ—à–Ω–µ–π –≥—Ä—É–ø–ø—ã
        region = f"{variant.CHROM}:{variant.POS}-{variant.POS}"
        ancestral_allele = None
        
        # –ü–æ–ª—É—á–∞–µ–º –∑–∞–ø–∏—Å–∏ –∏–∑ –≤–Ω–µ—à–Ω–µ–π –≥—Ä—É–ø–ø—ã –¥–ª—è —ç—Ç–æ–π –ø–æ–∑–∏—Ü–∏–∏
        for out_var in out_vcf(region):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø–æ–∑–∏—Ü–∏–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç —Ç–æ—á–Ω–æ
            if out_var.POS == variant.POS:
                # –ë–µ—Ä–µ–º –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–π –∞–ª–ª–µ–ª—å –≤–æ –≤–Ω–µ—à–Ω–µ–π –≥—Ä—É–ø–ø–µ
                # (–≤ –∏–¥–µ–∞–ª–µ –≤–Ω–µ—à–Ω—è—è –≥—Ä—É–ø–ø–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≥–æ–º–æ–∑–∏–≥–æ—Ç–Ω–∞)
                # gt_types: 0=HOM_REF, 1=HET, 2=HOM_ALT, 3=UNKNOWN
                gts = out_var.gt_types
                if np.mean(gts == 0) > 0.8: # –ü–æ—á—Ç–∏ –≤—Å–µ HOM_REF
                    ancestral_allele = out_var.REF
                elif np.mean(gts == 2) > 0.8: # –ü–æ—á—Ç–∏ –≤—Å–µ HOM_ALT
                    ancestral_allele = out_var.ALT[0]
                break
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –∞–ª–ª–µ–ª—å –≤–æ –≤–Ω–µ—à–Ω–µ–π –≥—Ä—É–ø–ø–µ - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–∞–π—Ç (–∏–ª–∏ –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å)
        # –í —Å—Ç–∞—Ç—å–µ –ø–æ –∫–∞–∫–∞–ø–æ —Ç–∞–∫–∏–µ —Å–∞–π—Ç—ã —á–∞—Å—Ç–æ –∏—Å–∫–ª—é—á–∞–ª–∏ –¥–ª—è —á–∏—Å—Ç–æ—Ç—ã Rxy
        if ancestral_allele is None:
            count_dropped += 1
            continue

        # –õ–û–ì–ò–ö–ê –ü–û–õ–Ø–†–ò–ó–ê–¶–ò–ò:
        # –ï—Å–ª–∏ Ancestral == –Ω–∞—à–µ–º—É ALT, –∑–Ω–∞—á–∏—Ç –Ω–∞—à REF –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ —è–≤–ª—è–µ—Ç—Å—è –º—É—Ç–∞—Ü–∏–µ–π (Derived).
        # –ù—É–∂–Ω–æ –ø–æ–º–µ–Ω—è—Ç—å –∏—Ö –º–µ—Å—Ç–∞–º–∏.
        
        if ancestral_allele == variant.ALT[0]:
            # 1. –ú–µ–Ω—è–µ–º REF –∏ ALT –º–µ—Å—Ç–∞–º–∏
            old_ref = variant.REF
            old_alt = variant.ALT[0]
            variant.REF = old_alt
            variant.ALT = [old_ref]
            
            # 2. –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≥–µ–Ω–æ—Ç–∏–ø—ã —É –≤—Å–µ—Ö –æ—Å–æ–±–µ–π
            # 0 -> 1 (–±—ã–ª REF, —Å—Ç–∞–ª ALT)
            # 1 -> 1 (–≥–µ—Ç–µ—Ä–æ–∑–∏–≥–æ—Ç–∞ –æ—Å—Ç–∞–µ—Ç—Å—è –≥–µ—Ç–µ—Ä–æ–∑–∏–≥–æ—Ç–æ–π)
            # 2 -> 0 (–±—ã–ª ALT, —Å—Ç–∞–ª REF)
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–µ –º–∞–Ω–∏–ø—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –º–∞—Å—Å–∏–≤–æ–º –≥–µ–Ω–æ—Ç–∏–ø–æ–≤ cyvcf2
            new_gts = variant.genotypes
            for i in range(len(new_gts)):
                gt = new_gts[i] # –§–æ—Ä–º–∞—Ç [allele1, allele2, is_phased]
                for j in range(2):
                    if gt[j] == 0: gt[j] = 1
                    elif gt[j] == 1: gt[j] = 0
                new_gts[i] = gt
            variant.genotypes = new_gts
            
            count_swapped += 1
        
        # –ï—Å–ª–∏ Ancestral == –Ω–∞—à–µ–º—É REF, –Ω–∏—á–µ–≥–æ –º–µ–Ω—è—Ç—å –Ω–µ –Ω–∞–¥–æ, ALT –∏ —Ç–∞–∫ Derived.
        # –ï—Å–ª–∏ Ancestral –Ω–µ —Å–æ–≤–ø–∞–ª –Ω–∏ —Å —á–µ–º (—Ç—Ä–µ—Ç–∏–π –∞–ª–ª–µ–ª—å), —Å–∞–π—Ç –æ–±—ã—á–Ω–æ –≤—ã–±—Ä–∞—Å—ã–≤–∞—é—Ç.
        elif ancestral_allele != variant.REF:
            count_dropped += 1
            continue
            
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∫—É –ø—Ä–µ–¥–∫–æ–≤–æ–≥–æ –∞–ª–ª–µ–ª—è –≤ INFO
        variant.INFO["AA"] = ancestral_allele
        w.write_record(variant)

    w.close()
    target_vcf.close()
    print(f"Done!")
    print(f"Total processed: {count_total}")
    print(f"Swapped (REF/ALT flip): {count_swapped}")
    print(f"Dropped (no outgroup data or mismatched): {count_dropped}")

if __name__ == "__main__":
    vcf_in = sys.argv[1]
    outgroup_vcf = sys.argv[2]
    vcf_out = sys.argv[3]
    polarize(vcf_in, outgroup_vcf, vcf_out)


==================================================

scripts/calc_rxy.py:
import sys
from cyvcf2 import VCF

vcf_path = sys.argv[1]
vcf = VCF(vcf_path)

# –î–æ–ø—É—Å—Ç–∏–º, –ø–µ—Ä–≤—ã–µ 10 –æ–±—Ä–∞–∑—Ü–æ–≤ - —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ, –æ—Å—Ç–∞–ª—å–Ω—ã–µ - –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ
counts = {'modern': 0, 'historical': 0}

for var in vcf:
    # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –≤—Ä–µ–¥–Ω—ã–µ (LoF/Moderate)
    impact = var.INFO.get('ANN').split('|')[2]
    if impact not in ['HIGH', 'MODERATE']: continue
    
    gts = var.gt_types # 0=HomRef, 1=Het, 2=HomAlt
    # –ï—Å–ª–∏ –º—ã –ø–æ–ª—è—Ä–∏–∑–æ–≤–∞–ª–∏ VCF, —Ç–æ Alt = Derived
    counts['modern'] += sum([1 for gt in gts[:10] if gt == 1]) + sum([2 for gt in gts[:10] if gt == 2])
    counts['historical'] += sum([1 for gt in gts[10:] if gt == 1]) + sum([2 for gt in gts[10:] if gt == 2])

rxy = counts['modern'] / counts['historical']
print(f"Rxy (Modern/Historical): {rxy}")


==================================================

scripts/run_final_slim.py:
import os
import subprocess
import matplotlib.pyplot as plt
import sys

OUT_PLOT = sys.argv[1]

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã (–∫–∞–∫ –≤ –≤–∞—à–µ–º –ø—Ä–∏–º–µ—Ä–µ)
N_ANC = 68440; N_BOT = 20; N_CUR = 16530
GEN_TIME = 4
Q = 10 # Scaling

N_ANC_S = int(N_ANC / Q); N_BOT_S = int(N_BOT); N_CUR_S = int(N_CUR / Q)
T_BOT_DUR_S = int((10895 / GEN_TIME) / Q)
T_REC_AGO_S = int((114219 / GEN_TIME) / Q)
T_START_BOT = 5000
T_START_REC = T_START_BOT + T_BOT_DUR_S
T_END = T_START_REC + T_REC_AGO_S

slim_code = f"""
initialize() {{
    initializeMutationRate(1e-7 * {Q}); 
    initializeMutationType("m1", 0.5, "f", 0.0);
    initializeMutationType("m2", 0.05, "g", -0.05, 0.2); 
    initializeGenomicElementType("g1", c(m1, m2), c(1.0, 2.0));
    for (i in 0:49) {{ initializeGenomicElement(g1, i*2000, i*2000 + 999); }}
    initializeRecombinationRate(1e-8 * {Q});
}}
1 early() {{ sim.addSubpop("p1", {N_ANC_S}); }}
1:{T_END} late() {{
    if (community.tick % 100 == 0) {{
        if (p1.individualCount > 0) {{
            inds = p1.individuals;
            total_m2 = mean(inds.countOfMutationsOfType(m2));
            cat(community.tick + "," + total_m2 + "\\n");
        }}
    }}
}}
{T_START_BOT} early() {{ p1.setSubpopulationSize({N_BOT_S}); }}
{T_START_REC} early() {{ p1.setSubpopulationSize({N_CUR_S}); }}
"""

with open("temp_model.slim", "w") as f: f.write(slim_code)
res = subprocess.run(["slim", "temp_model.slim"], capture_output=True, text=True)

gens, loads = [], []
for line in res.stdout.splitlines():
    if "," in line and not line.startswith("Gen"):
        p = line.split(",")
        try: gens.append(int(p[0])); loads.append(float(p[1]))
        except: pass

if len(gens) > 0:
    plt.figure(figsize=(10, 6))
    plt.plot(gens, loads, color="red")
    plt.axvline(x=T_START_BOT, linestyle='--'); plt.axvline(x=T_START_REC, linestyle='--')
    plt.savefig(OUT_PLOT)


==================================================

scripts/detect_sex_scaffolds.py:
import sys
import pandas as pd

blast_z_file = sys.argv[1]
blast_w_file = sys.argv[2]
output_file = sys.argv[3]

def get_top_scaffolds(blast_file, top_n=10):
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø—É—Å—Ç–æ–π –ª–∏ —Ñ–∞–π–ª
        import os
        if os.path.getsize(blast_file) == 0:
            return []
            
        df = pd.read_csv(blast_file, sep='\t', header=None, 
                         names=['qseqid', 'sseqid', 'pident', 'length', 'mismatch', 'gapopen', 
                                'qstart', 'qend', 'sstart', 'send', 'evalue', 'bitscore'])
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∞–±—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        df = df[(df['pident'] > 80) & (df['length'] > 500)]
        
        if df.empty:
            return []

        # –°—É–º–º–∏—Ä—É–µ–º –¥–ª–∏–Ω—É –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–π
        scaffold_counts = df.groupby('sseqid')['length'].sum().sort_values(ascending=False)
        return scaffold_counts.head(top_n).index.tolist()
    except Exception as e:
        print(f"Warning processing {blast_file}: {e}")
        return []

z_scaffolds = get_top_scaffolds(blast_z_file)
w_scaffolds = get_top_scaffolds(blast_w_file)

sex_scaffolds = sorted(list(set(z_scaffolds + w_scaffolds)))

with open(output_file, 'w') as f:
    for scaf in sex_scaffolds:
        f.write(f"{scaf}\n")

print(f"Detected {len(sex_scaffolds)} sex scaffolds.")


==================================================

scripts/dadi_inference.py:
import sys
import dadi
import matplotlib.pyplot as plt
import numpy as np

vcf_file = sys.argv[1]
pop_map = sys.argv[2]
out_params = sys.argv[3]
out_plot = sys.argv[4]

# 1. –ó–∞–≥—Ä—É–∑–∫–∞
dd = dadi.Misc.make_data_dict_vcf(vcf_file, pop_map)
# –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–µ–∫—Ü–∏—é –ø–æ–º–µ–Ω—å—à–µ (20), —á—Ç–æ–±—ã —É–º–µ–Ω—å—à–∏—Ç—å —à—É–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
fs = dadi.Spectrum.from_data_dict(dd, ['Spoonbill'], [20], polarized=False)

# –ú–ê–°–ö–ò–†–û–í–ê–ù–ò–ï: –£–±–∏—Ä–∞–µ–º —Å–∏–Ω–≥–ª–µ—Ç–æ–Ω—ã (–æ—à–∏–±–∫–∏ —Å–µ–∫–≤–µ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è)
fs.mask[1] = True 
fs.mask[-1] = True

def bottleneck(params, ns, pts):
    nuB, nuF, TB, TF = params
    xx = dadi.Numerics.default_grid(pts)
    phi = dadi.PhiManip.phi_1D(xx)
    phi = dadi.Integration.one_pop(phi, xx, TB, nuB)
    phi = dadi.Integration.one_pop(phi, xx, TF, nuF)
    return dadi.Spectrum.from_phi(phi, ns, (xx,))

pts_l = [30, 40, 50]
func_ex = dadi.Numerics.make_extrap_log_func(bottleneck)

p0 = [0.1, 1.0, 0.1, 0.1]
lower_bound = [1e-3, 1e-2, 1e-3, 1e-3]
upper_bound = [10, 100, 5, 5] # –†–∞—Å—à–∏—Ä–∏–ª–∏ –≥—Ä–∞–Ω–∏—Ü—ã

best_ll = -np.inf
best_params = p0
best_model = None

# –ë—ã—Å—Ç—Ä—ã–π –ø—Ä–æ–≥–æ–Ω –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
print("Optimizing...")
for i in range(15):
    p_guess = dadi.Misc.perturb_params(p0, fold=1)
    try:
        popt = dadi.Inference.optimize_log(p_guess, fs, func_ex, pts_l, 
                                           lower_bound=lower_bound, 
                                           upper_bound=upper_bound, 
                                           maxiter=20, verbose=0)
        model = func_ex(popt, fs.sample_sizes, pts_l)
        ll = dadi.Inference.ll_multinom(model, fs)
        if ll > best_ll:
            best_ll = ll
            best_params = popt
            best_model = model
    except: pass

if best_model is None:
    best_model = func_ex(p0, fs.sample_sizes, pts_l)

# –†–ò–°–û–í–ê–ù–ò–ï
fig = plt.figure(figsize=(10, 8))
dadi.Plotting.plot_1d_comp_multinom(best_model, fs)
plt.savefig(out_plot, dpi=150)

# –†–∞—Å—á–µ—Ç (Theta based on unmasked sites)
theta = dadi.Inference.optimal_sfs_scaling(best_model, fs)
# N_anc calculation
mu = 4.6e-9
L = 5000000 # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –¥–ª–∏–Ω–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –≥–µ–Ω–æ–º–∞ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤
N_anc = theta / (4 * mu * L)
nuB, nuF, TB, TF = best_params

with open(out_params, 'w') as f:
    f.write(f"N_ANC={int(N_anc)}\n")
    f.write(f"N_BOT={int(N_anc*nuB)}\n")
    f.write(f"N_CUR={int(N_anc*nuF)}\n")
    f.write(f"T_BOT_DUR_GEN={int(TB*2*N_anc)}\n")
    f.write(f"T_REC_AGO_GEN={int(TF*2*N_anc)}\n")


==================================================

scripts/calc_thresholds.py:
import sys
import numpy as np
from cyvcf2 import VCF

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python scripts/calc_thresholds.py resources/merged.vcf
vcf_file = sys.argv[1]

print(f"Reading {vcf_file} to calculate depth stats...")
depths = []
vcf = VCF(vcf_file)

# –ß–∏—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ 100,000 –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
for i, variant in enumerate(vcf):
    if i > 100000: break
    dp = variant.INFO.get('DP')
    if dp:
        depths.append(dp)

depths = np.array(depths)
mean_dp = np.mean(depths)
std_dp = np.std(depths)

print("\n" + "="*30)
print(f"  MEAN DEPTH (Global): {mean_dp:.2f}")
print("="*30)
print("Recommended config settings:")
print(f"  min_depth: {int(mean_dp * 0.3)}  (Mean * 0.3)")
print(f"  max_depth: {int(mean_dp * 1.8)}  (Mean * 1.8 - cutoff for paralogs)")
print("="*30 + "\n")


==================================================

scripts/plot_windows.py:
import sys
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

pi_file = sys.argv[1]
tajima_file = sys.argv[2]
out_plot = sys.argv[3]

# –ß–∏—Ç–∞–µ–º Pi
try:
    df_pi = pd.read_csv(pi_file, sep='\t')
    df_taj = pd.read_csv(tajima_file, sep='\t')
except:
    plt.figure(); plt.savefig(out_plot); sys.exit()

fig, axes = plt.subplots(2, 1, figsize=(12, 10))

# –ì—Ä–∞—Ñ–∏–∫ 1: Pi
# –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è (–æ—à–∏–±–∫–∏) –∏ NaN
df_pi = df_pi[df_pi['PI'] < 0.1].dropna()
sns.histplot(df_pi['PI'], bins=50, color='teal', ax=axes[0], kde=True)
axes[0].set_title('Nucleotide Diversity (Pi) Distribution')
axes[0].set_xlabel('Pi (per site)')

# –ì—Ä–∞—Ñ–∏–∫ 2: Tajima's D
df_taj = df_taj.dropna()
sns.histplot(df_taj['TajimaD'], bins=50, color='purple', ax=axes[1], kde=True)
axes[1].set_title("Tajima's D Distribution")
axes[1].set_xlabel("Tajima's D")
axes[1].axvline(x=0, color='black', linestyle='--')

plt.tight_layout()
plt.savefig(out_plot)


==================================================

scripts/plot_nj_tree.py:
import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.cluster.hierarchy import dendrogram, linkage
from scipy.spatial.distance import squareform
import os

def plot_nj_tree(mdist_file, id_file, output_png):
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ (IID)
    # PLINK .mdist.id —Å–æ–¥–µ—Ä–∂–∏—Ç FID –≤ –ø–µ—Ä–≤–æ–º —Å—Ç–æ–ª–±—Ü–µ –∏ IID –≤–æ –≤—Ç–æ—Ä–æ–º
    try:
        ids_df = pd.read_csv(id_file, sep='\s+', header=None)
        sample_names = ids_df[1].values
    except Exception as e:
        print(f"Error reading IDs: {e}")
        sys.exit(1)

    # 2. –ó–∞–≥—Ä—É–∑–∫–∞ –º–∞—Ç—Ä–∏—Ü—ã –¥–∏—Å—Ç–∞–Ω—Ü–∏–π
    try:
        dist_matrix = np.loadtxt(mdist_file)
    except Exception as e:
        print(f"Error reading distance matrix: {e}")
        sys.exit(1)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
    if dist_matrix.shape[0] != len(sample_names):
        print("Warning: Matrix dimensions do not match number of IDs. Attempting to fix...")
        # –ò–Ω–æ–≥–¥–∞ PLINK –≤—ã–≤–æ–¥–∏—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã, –∑–∞–≥—Ä—É–∑–∏–º —á–µ—Ä–µ–∑ pandas –µ—Å–ª–∏ numpy —Å–±–æ–∏—Ç
        dist_matrix = pd.read_csv(mdist_file, sep='\s+', header=None).values

    # 3. –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã –≤ –∫–æ–Ω–¥–µ–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è scipy
    # squareform —É–±–µ–∂–¥–∞–µ—Ç—Å—è, —á—Ç–æ –º–∞—Ç—Ä–∏—Ü–∞ —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–∞ –∏ –Ω–∞ –¥–∏–∞–≥–æ–Ω–∞–ª–∏ –Ω—É–ª–∏
    np.fill_diagonal(dist_matrix, 0)
    condensed_dist = squareform(dist_matrix)

    # 4. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –¥–µ—Ä–µ–≤–∞ (–º–µ—Ç–æ–¥ 'average' —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç UPGMA, 
    # 'weighted' –±–ª–∏–∑–æ–∫ –∫ NJ –ø–æ –ª–æ–≥–∏–∫–µ –≤–∑–≤–µ—à–∏–≤–∞–Ω–∏—è —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π)
    Z = linkage(condensed_dist, method='average')

    # 5. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    plt.figure(figsize=(12, 10))
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —ç—Å—Ç–µ—Ç–∏–∫–∏ (—Ü–≤–µ—Ç–∞ –∏ –ª–∏–Ω–∏–∏)
    dendrogram(
        Z, 
        labels=sample_names, 
        orientation='left',  # –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –¥–µ—Ä–µ–≤–æ –ª—É—á—à–µ —á–∏—Ç–∞–µ—Ç—Å—è
        leaf_font_size=10,
        color_threshold=np.mean(Z[:, 2]), # –†–∞—Å–∫—Ä–∞—Å–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
        above_threshold_color='grey'
    )

    plt.title("Genetic Structure: Neighbor-Joining (IBS Distance)", fontsize=15)
    plt.xlabel("Genetic Distance (1-IBS)", fontsize=12)
    plt.grid(axis='x', linestyle='--', alpha=0.5)
    
    # –£–±–∏—Ä–∞–µ–º —Ä–∞–º–∫–∏ –¥–ª—è —á–∏—Å—Ç–æ—Ç—ã
    plt.gca().spines['top'].set_visible(False)
    plt.gca().spines['right'].set_visible(False)

    plt.tight_layout()
    plt.savefig(output_png, dpi=300)
    print(f"NJ tree successfully saved to {output_png}")

if __name__ == "__main__":
    if len(sys.argv) < 4:
        print("Usage: python plot_nj_tree.py <matrix.mdist> <matrix.mdist.id> <output.png>")
        sys.exit(1)
    
    mdist_f = sys.argv[1]
    id_f = sys.argv[2]
    out_f = sys.argv[3]
    
    plot_nj_tree(mdist_f, id_f, out_f)


==================================================

README.md:
---

# –ü–∞–π–ø–ª–∞–π–Ω –ø–æ–ø—É–ª—è—Ü–∏–æ–Ω–Ω–æ–π –≥–µ–Ω–æ–º–∏–∫–∏ –∫—É–ª–∏–∫–∞-–ª–æ–ø–∞—Ç–µ–Ω—è (*Calidris pygmaea*)

–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–π —Ü–∏–∫–ª (–Ω–∞ –±–∞–∑–µ **Snakemake**) –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–ª–Ω–æ–≥–µ–Ω–æ–º–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (WGS) –∏—Å—á–µ–∑–∞—é—â–µ–≥–æ –≤–∏–¥–∞ ‚Äî –∫—É–ª–∏–∫–∞-–ª–æ–ø–∞—Ç–µ–Ω—è. –ü–∞–π–ø–ª–∞–π–Ω —Ä–µ—à–∞–µ—Ç –∑–∞–¥–∞—á–∏ –æ—Ç –ø–µ—Ä–≤–∏—á–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–æ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–π –∏—Å—Ç–æ—Ä–∏–∏ –∏ –æ—Ü–µ–Ω–∫–∏ –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∑–¥–æ—Ä–æ–≤—å—è –ø–æ–ø—É–ª—è—Ü–∏–∏.

## üß¨ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏ —ç—Ç–∞–ø—ã –∞–Ω–∞–ª–∏–∑–∞

–ü–∞–π–ø–ª–∞–π–Ω —Ä–∞–∑–¥–µ–ª–µ–Ω –Ω–∞ 8 –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –±–ª–æ–∫–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤—ã—á–∏—Å–ª–µ–Ω–∏–π.

### 1. –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª–æ–≤—ã—Ö —Ö—Ä–æ–º–æ—Å–æ–º (Sex ID)
–ü–æ—Å–∫–æ–ª—å–∫—É —Å–±–æ—Ä–∫–∞ –≥–µ–Ω–æ–º–∞ –∫—É–ª–∏–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–∫–∞—Ñ—Ñ–æ–ª–¥–æ–≤, –ø–æ–ª–æ–≤—ã–µ —Ö—Ä–æ–º–æ—Å–æ–º—ã (Z –∏ W) –Ω–µ –≤—Å–µ–≥–¥–∞ –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω—ã.
*   **–ú–µ—Ç–æ–¥:** –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —ç—Ç–∞–ª–æ–Ω–Ω—ã—Ö —Ö—Ä–æ–º–æ—Å–æ–º –ó–µ–±—Ä–æ–≤–æ–π –∞–º–∞–¥–∏–Ω—ã (Z) –∏ –ö—É—Ä–∏—Ü—ã (W) —Å NCBI.
*   **–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç:** `BLASTn` –ø—Ä–æ–≤–æ–¥–∏—Ç –ø–æ–∏—Å–∫ –≥–æ–º–æ–ª–æ–≥–∏—á–Ω—ã—Ö —É—á–∞—Å—Ç–∫–æ–≤ –≤ –∏—Å—Å–ª–µ–¥—É–µ–º–æ–º –≥–µ–Ω–æ–º–µ.
*   **–†–µ–∑—É–ª—å—Ç–∞—Ç:** –°–ø–∏—Å–æ–∫ —Å–∫–∞—Ñ—Ñ–æ–ª–¥–æ–≤, –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ —è–≤–ª—è—é—â–∏—Ö—Å—è –ø–æ–ª–æ–≤—ã–º–∏ —Ö—Ä–æ–º–æ—Å–æ–º–∞–º–∏, –¥–ª—è –∏—Ö –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ —É—á–µ—Ç–∞ –∏–ª–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏—è.

### 2. –ö–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è (QC)
–ü—Ä–µ–≤—Ä–∞—â–µ–Ω–∏–µ "—Å—ã—Ä–æ–≥–æ" VCF –≤ –æ—á–∏—â–µ–Ω–Ω—ã–π –º–∞—Å—Å–∏–≤ –¥–∞–Ω–Ω—ã—Ö.
*   **–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã:** `bcftools`, `vcftools`.
*   **–õ–æ–≥–∏–∫–∞:** –£–¥–∞–ª–µ–Ω–∏–µ –∏–Ω–¥–∏–ª–µ–π, –º—É–ª—å—Ç–∏–∞–ª–ª–µ–ª—å–Ω—ã—Ö —Å–∞–π—Ç–æ–≤ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∫–∞—á–µ—Å—Ç–≤—É (QUAL).
*   **–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å:** –ü–∞–π–ø–ª–∞–π–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç "–≥–∏–±—Ä–∏–¥–Ω—ã–π" –ø–æ–¥—Ö–æ–¥:
    *   **Full VCF:** –°–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ SNP –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –º—É—Ç–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –≥—Ä—É–∑–∞ –∏ Pi.
    *   **Pruned VCF:** –ü—Ä–æ—Ä–µ–∂–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö (LD-pruning), –≥–¥–µ —É–¥–∞–ª–µ–Ω—ã —Å—Ü–µ–ø–ª–µ–Ω–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã, –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ PCA –∏ dadi.

### 3. –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø–æ–ø—É–ª—è—Ü–∏–∏ (Structure & PCA)
–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–π –æ–¥–Ω–æ—Ä–æ–¥–Ω–æ—Å—Ç–∏ 22 –æ—Å–æ–±–µ–π.
*   **PCA (Principal Component Analysis):** –°–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–º–æ—â—å—é `PLINK` –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –æ—Å–æ–±–µ–π.
*   **sNMF (LEA R-package):** –û—Ü–µ–Ω–∫–∞ –¥–æ–ª–µ–π –ø—Ä–µ–¥–∫–æ–≤—ã—Ö –ø–æ–ø—É–ª—è—Ü–∏–π –∏ —Ä–∞—Å—á–µ—Ç –∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —á–∏—Å–ª–∞ –≥—Ä—É–ø–ø (K).
*   **–†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º:** –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω –º–µ—Ö–∞–Ω–∏–∑–º –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è —Å–∫–∞—Ñ—Ñ–æ–ª–¥–æ–≤ "–Ω–∞ –ª–µ—Ç—É" (mapping to Chromosome 1), —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–±—Ö–æ–¥–∏—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è PLINK 1.9 –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å–æ —Å–±–æ—Ä–∫–∞–º–∏ scaffold-level.

### 4. –†–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–π –∏—Å—Ç–æ—Ä–∏–∏ (dadi)
–ú–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç–∏ –ø–æ–ø—É–ª—è—Ü–∏–∏ –≤ –ø—Ä–æ—à–ª–æ–º.
*   **–ú–µ—Ç–æ–¥:** –ê–Ω–∞–ª–∏–∑ —Å–ø–µ–∫—Ç—Ä–∞ —á–∞—Å—Ç–æ—Ç –∞–ª–ª–µ–ª–µ–π (SFS).
*   **–ú–æ–¥–µ–ª—å:** "Bottleneck-Recovery" (—Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç–∏ —Å –ø–æ—Å–ª–µ–¥—É—é—â–∏–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º).
*   **–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è:** –ú–æ–¥–µ–ª—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã ($N_e$, –≤—Ä–µ–º—è —Å–æ–±—ã—Ç–∏–π) –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–∞–π–ª –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —ç—Ç–∞–ø–∞ (SLiM).

### 5. –ú—É—Ç–∞—Ü–∏–æ–Ω–Ω—ã–π –≥—Ä—É–∑ (Mutational Load)
–û—Ü–µ–Ω–∫–∞ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –≤—Ä–µ–¥–Ω—ã—Ö –º—É—Ç–∞—Ü–∏–π –≤ –≥–µ–Ω–æ–º–µ.
*   **–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç:** `SnpEff`.
*   **–õ–æ–≥–∏–∫–∞:** –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è SNP –Ω–∞ –æ—Å–Ω–æ–≤–µ GFF-—Ñ–∞–π–ª–∞. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –º—É—Ç–∞—Ü–∏–π –Ω–∞:
    *   *Synonymous (—Ç–∏—Ö–∏–µ)* ‚Äî –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π —Ñ–æ–Ω.
    *   *Missense (—Å–ª–∞–±–æ –≤—Ä–µ–¥–Ω—ã–µ)* ‚Äî —É–º–µ—Ä–µ–Ω–Ω–æ–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ.
    *   *Loss-of-Function (—Å–∏–ª—å–Ω–æ –≤—Ä–µ–¥–Ω—ã–µ)* ‚Äî –ø–æ–ª–æ–º–∫–∞ –≥–µ–Ω–∞.
*   **–ú–µ—Ç—Ä–∏–∫–∞:** –†–∞—Å—á–µ—Ç —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è –≤—Ä–µ–¥–Ω—ã—Ö –º—É—Ç–∞—Ü–∏–π –∫ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–º –¥–ª—è –∫–∞–∂–¥–æ–π –æ—Å–æ–±–∏.

### 6. –≠–≤–æ–ª—é—Ü–∏–æ–Ω–Ω–æ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ (SLiM 4)
–ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø–æ—Ç–µ–∑—ã –æ "–≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–π –æ—á–∏—Å—Ç–∫–µ" (Purging).
*   **–ú–µ—Ç–æ–¥:** –ò–Ω–¥–∏–≤–∏–¥—É—É–º-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ (Forward-in-time simulation).
*   **–°–≤—è–∑–∫–∞:** SLiM –ø–æ–ª—É—á–∞–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –¥–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ `dadi`.
*   **–ó–∞–¥–∞—á–∞:** –ü–æ–Ω—è—Ç—å, –ø—Ä–∏–≤–µ–ª–æ –ª–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–µ "–±—É—Ç—ã–ª–æ—á–Ω–æ–µ –≥–æ—Ä–ª—ã—à–∫–æ" –∫ –≤—ã–º—ã–≤–∞–Ω–∏—é –≤—Ä–µ–¥–Ω—ã—Ö –º—É—Ç–∞—Ü–∏–π –∏–ª–∏ –∫ –∏—Ö –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—é.

### 7. –ê–Ω–∞–ª–∏–∑ –∏–Ω–±—Ä–∏–¥–∏–Ω–≥–∞ (ROH)
–ü–æ–∏—Å–∫ —É—á–∞—Å—Ç–∫–æ–≤ –≥–æ–º–æ–∑–∏–≥–æ—Ç–Ω–æ—Å—Ç–∏ (Runs of Homozygosity).
*   **–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç:** `PLINK --homozyg`.
*   **–†–µ–∑—É–ª—å—Ç–∞—Ç:** –†–∞—Å—á–µ—Ç –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –∏–Ω–±—Ä–∏–¥–∏–Ω–≥–∞ $F_{ROH}$ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏ —Å–ø–∞—Ä–∏–≤–∞–Ω–∏—è —Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω–∏–∫–æ–≤. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –¥—Ä–µ–≤–Ω–∏–π –∏–Ω–±—Ä–∏–¥–∏–Ω–≥ (–∫–æ—Ä–æ—Ç–∫–∏–µ —É—á–∞—Å—Ç–∫–∏) –∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π (–¥–ª–∏–Ω–Ω—ã–µ —É—á–∞—Å—Ç–∫–∏).

### 8. –ì–µ–Ω–æ–º–Ω–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ (Genomic Windows)
–ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –≤–¥–æ–ª—å –≥–µ–Ω–æ–º–∞.
*   **–ú–µ—Ç—Ä–∏–∫–∏:** –ù—É–∫–ª–µ–æ—Ç–∏–¥–Ω–æ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ ($\pi$) –∏ $Tajima's D$.
*   **–û–∫–Ω–∞:** –†–∞—Å—á–µ—Ç –≤ —Å–∫–æ–ª—å–∑—è—â–∏—Ö –æ–∫–Ω–∞—Ö –ø–æ 50 –∫–±.
*   **–¶–µ–ª—å:** –ü–æ–∏—Å–∫ "–æ—Å—Ç—Ä–æ–≤–æ–≤ –æ—Ç–±–æ—Ä–∞" ‚Äî —É—á–∞—Å—Ç–∫–æ–≤ –≥–µ–Ω–æ–º–∞, –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω—ã—Ö –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ñ–æ—Ä–º–∞ –∫–ª—é–≤–∞).

---

## üõ† –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫
*   **Workflow Manager:** Snakemake
*   **Languages:** Python 3, R, Bash
*   **Genomics Tools:** bcftools, vcftools, PLINK 1.9, BLAST+, SnpEff, SLiM 4, dadi
*   **Visualisation:** Matplotlib, Seaborn, LEA (R)

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞
*   `Snakefile` ‚Äî –ª–æ–≥–∏–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞.
*   `config/config.yaml` ‚Äî –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∏ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º.
*   `scripts/` ‚Äî –∫–∞—Å—Ç–æ–º–Ω—ã–µ Python/R —Å–∫—Ä–∏–ø—Ç—ã –¥–ª—è —Ä–∞—Å—á–µ—Ç–æ–≤ –∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤.
*   `resources/` ‚Äî –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (VCF, FASTA, GFF).
*   `results/` ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞–≤–∞–µ–º–∞—è –ø–∞–ø–∫–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ (–≥—Ä–∞—Ñ–∏–∫–∏, —Ç–∞–±–ª–∏—Ü—ã, –ª–æ–≥–∏).

---
*–ü–∞–π–ø–ª–∞–π–Ω –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ —É—Å–ª–æ–≤–∏—è—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã—Ö –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ (WSL/Desktop) –∑–∞ —Å—á–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Ä–µ–∂–∏–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö (LD-pruning) –∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–ø—É–ª—è—Ü–∏–π –≤ —Å–∏–º—É–ª—è—Ü–∏—è—Ö.*


==================================================

